## ü§ó Diffusers
- https://github.com/huggingface/diffusers
- ü§ó Diffusers ÊòØÊúÄÂÖàÈÄ≤ÁöÑÈ†êË®ìÁ∑¥Êì¥Êï£Ê®°ÂûãÁöÑÈ¶ñÈÅ∏Â∫´ÔºåÁî®ÊñºÁîüÊàêÂúñÂÉè„ÄÅÈü≥Ë®äÁîöËá≥ÂàÜÂ≠êÁöÑ 3D ÁµêÊßã„ÄÇ
- ÁÑ°Ë´ñÊÇ®ÊòØÂú®Â∞ãÊâæÁ∞°ÂñÆÁöÑÊé®ÁêÜËß£Ê±∫ÊñπÊ°àÈÇÑÊòØË®ìÁ∑¥Ëá™Â∑±ÁöÑÊì¥Êï£Ê®°ÂûãÔºå ü§ó Diffusers ÈÉΩÊòØ‰∏ÄÂÄãÊîØÊè¥ÂÖ©ËÄÖÁöÑÊ®°ÁµÑÂåñÂ∑•ÂÖ∑ÁÆ±„ÄÇ
- ÊàëÂÄëÁöÑÂ∫´Âú®Ë®≠Ë®àÊôÇÊ≥®ÈáçÂèØÁî®ÊÄßËÄå‰∏çÊòØÊÄßËÉΩÔºåÁ∞°ÂñÆËÄå‰∏çÊòØÁ∞°ÂñÆÔºå‰ª•ÂèäÂèØÂÆöË£ΩÊÄßËÄå‰∏çÊòØÊäΩË±°„ÄÇ

## ü§ó Diffusers Êèê‰æõ‰∏âÂÄãÊ†∏ÂøÉÂÖÉ‰ª∂Ôºö
- `ÊúÄÂÖàÈÄ≤ÁöÑÊì¥Êï£ÁÆ°ÈÅì(State-of-the-art diffusion pipelines)` ==> Âè™ÈúÄÂπæË°å‰ª£Á¢ºÂç≥ÂèØÂú®Êé®ÁêÜ‰∏≠ÈÅãË°å„ÄÇ
  - The DiffusionPipeline is a high-level end-to-end class designed to rapidly generate samples from pretrained diffusion models for inference.
- `ÂèØ‰∫íÊèõÁöÑÈõúË®äË™øÂ∫¶Âô®(Interchangeable noise schedulers)` ==> ÈÅ©Áî®Êñº‰∏çÂêåÁöÑÊì¥Êï£ÈÄüÂ∫¶ÂíåËº∏Âá∫ÂìÅË≥™„ÄÇ
  - Many different schedulers - algorithms that control how noise is added for training, and how to generate denoised images during inference.
- `È†êË®ìÁ∑¥Ê®°Âûã(Pretrained models)`ÂèØÁî®‰ΩúÊßãÂª∫ÂçÄÂ°ä(building blocks)Ôºå‰∏¶Ëàá`Ë™øÂ∫¶Âô®(schedulers)`ÁµêÂêà‰ΩøÁî®ÔºåÁî®ÊñºÂâµÂª∫ÊÇ®Ëá™Â∑±ÁöÑÁ´ØÂà∞Á´ØÊì¥Êï£Á≥ªÁµ±„ÄÇ
  - Popular pretrained model architectures and modules that can be used as building blocks for creating diffusion systems.

## diffusers_ÂØ¶Êà∞1 ==> Êõ¥Â§öÂ≠∏Áøí Ë´ãÂèÉÈñ± https://huggingface.co/docs/diffusers/index
- https://github.com/huggingface/diffusers
- [‰ΩøÁî®T4 GPU](diffusers_ÂØ¶Êà∞1_20250609_2.ipynb)
```python
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", torch_dtype=torch.float16)
pipeline.to("cuda")
pipeline("An image of a squirrel in Picasso style").images[0]
```

```python
from diffusers import DDPMScheduler, UNet2DModel
from PIL import Image
import torch

scheduler = DDPMScheduler.from_pretrained("google/ddpm-cat-256")
model = UNet2DModel.from_pretrained("google/ddpm-cat-256").to("cuda")
scheduler.set_timesteps(50)

sample_size = model.config.sample_size
noise = torch.randn((1, 3, sample_size, sample_size), device="cuda")
input = noise

for t in scheduler.timesteps:
    with torch.no_grad():
        noisy_residual = model(input, t).sample
        prev_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample
        input = prev_noisy_sample

image = (input / 2 + 0.5).clamp(0, 1)
image = image.cpu().permute(0, 2, 3, 1).numpy()[0]
image = Image.fromarray((image * 255).round().astype("uint8"))
image
```
