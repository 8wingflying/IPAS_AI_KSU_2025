## ä½¿ç”¨å…§å»ºMODEL
```
from tensorflow.keras.applications import Xception
xception = Xception()
xception.summary()
```
- [Keras å…§å»ºCNN MODEL| Keras Applications](https://keras.io/api/applications/)
## CNN Model
- ğŸ“[A Survey of the Recent Architectures of Deep Convolutional Neural Networks(abs/1901.06032)](https://arxiv.org/abs/1901.06032)
- ğŸ“[A Comprehensive Survey on Architectural Advances in Deep CNNs: Challenges, Applications, and Emerging Research Directions()](https://arxiv.org/abs/2503.16546)
- ğŸ–Šï¸LeNet(1989)
- ğŸ“…LeNet-5 (1998)
- é‡è¦ç™¼å±•
  - GPU (2006)
  - NVIDIA (2007)
  - ImageNet(2010-2017) https://image-net.org/
- AlexNet(2012)
  - AlexNet was trained in parallel on two NVIDIA GTX 580 GPUs 
- ZFNet(2013)
- â­GoogLeNet/Inception(2014)
  -  Inception V2 ==> V3 ==> V4 
- VGGNet (2014)
- Residual Neural Network (ResNet)(2015) |
- DenseNet(2016)
  - [Densely Connected Convolutional Networks(arXiv:1608.06993)](https://arxiv.org/abs/1608.06993)
  - ç›¸è¼ƒæ–¼ResNet, DenseNet å¯ç”¨æ›´å°‘çš„è¨“ç·´åƒæ•¸å–å¾—æ›´ä½³çš„æº–ç¢ºç‡
  - CVPR 2017 æœ€ä½³è«–æ–‡
  - Keras æä¾›æ•¸å€‹DenseNet ç‰ˆæœ¬ä¾›æˆ‘å€‘ä½¿ç”¨ï¼š DenseNet 121 ã€DenseNet 169 ã€DenseNet201
- SENetï¼ˆSqueeze-and-Excitation Networksï¼‰(2017)
  - ImageNet 2017 ç«¶è³½å† è»
  - [è«–æ–‡ Squeeze-and-Excitation Networks(arXiv:1709.01507)](https://arxiv.org/abs/1709.01507)
  - https://github.com/hujie-frank/SENet
- ShuffleNet(2017) ä¸€ç¨®é‡å°ç§»å‹•è¨­å‚™çš„æ¥µé«˜æ•ˆå·ç©ç¥ç¶“ç¶²è·¯
  - [è«–æ–‡ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices(arXiv:1707.01083)](https://arxiv.org/abs/1707.01083) 

## Vision Transformers (ViT)ç³»åˆ—æ¨¡å‹ 2020-2021
- æ‡‰ç”¨Transformers åˆ°é›»è…¦è¦–è¦ºçš„å„ç¨®æ¨¡å‹
- Vision Transformers (ViTs)(2020)
  - [è«–æ–‡An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale(arXiv:2010.11929)](https://arxiv.org/abs/2010.11929)
  - Vision Transformer architecture comprises several key stages:
    - Image Patching and Embedding
    - Positional Encoding
    - Transformer Encoder
    - Classification Head (MLP Head) 
  - https://blog.csdn.net/abc13526222160/article/details/131228810
- DeiT (Data-efficient Image Transformer)
  - [[2012.12877]Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)
  - https://blog.csdn.net/abc13526222160/article/details/132339050
- å¾®è»ŸSwin Transformer
  - [[2103.14030] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows ](https://arxiv.org/abs/2103.14030)
  - https://www.geeksforgeeks.org/swin-transformer/
- å¾®è»Ÿ CvT (Convolutional Vision Transformer)
  - [[2103.15808] CvT: Introducing Convolutions to Vision Transformers ](https://arxiv.org/abs/2103.15808)
  - https://zhuanlan.zhihu.com/p/583450848
- T2T-ViT (Tokens-to-Token Vision Transformer)
  - [[2101.11986] Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet](https://arxiv.org/abs/2101.11986)
  - https://zhuanlan.zhihu.com/p/460938219  

## Vision Language Models ==> é‚å‘ MLLM(å¤šæ¨¡æ…‹å¤§èªè¨€æ¨¡å‹) 2021/2022
- CLIP (Contrastive Language-Image Pre-training)
  - å°æ¯”èªè¨€-åœ–åƒé è¨“ç·´ ï¼ˆCLIPï¼‰ æ˜¯ä¸€ç¨®ä½¿ç”¨å°æ¯”ç›®æ¨™è¨“ç·´ä¸€å°ç¥ç¶“ç¶²è·¯æ¨¡å‹çš„æŠ€è¡“ï¼Œä¸€å€‹ç”¨æ–¼åœ–åƒç†è§£ï¼Œä¸€å€‹ç”¨æ–¼æ–‡æœ¬ç†è§£ã€‚
  - é€™ç¨®æ–¹æ³•åœ¨å¤šå€‹é ˜åŸŸå¯¦ç¾äº†å»£æ³›çš„æ‡‰ç”¨ï¼ŒåŒ…æ‹¬è·¨æ¨¡æ…‹æª¢ç´¢ ã€æ–‡æœ¬åˆ°åœ–åƒç”Ÿæˆ
  - https://en.wikipedia.org/wiki/Contrastive_Language-Image_Pre-training
  - [Contrastive Language-Image Pre-Training with Knowledge Graphs](https://arxiv.org/abs/2210.08901) 
- ALIGN (A Large-scale ImaGe and Noisy-text)
  - [Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision](https://arxiv.org/abs/2102.05918) 
- BLIP (Bootstrapping Language-Image Pre-training)
  - [BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://arxiv.org/abs/2201.12086) 
