## CNN Model
- ğŸ“[A Survey of the Recent Architectures of Deep Convolutional Neural Networks(abs/1901.06032)](https://arxiv.org/abs/1901.06032)
- ğŸ“[A Comprehensive Survey on Architectural Advances in Deep CNNs: Challenges, Applications, and Emerging Research Directions()](https://arxiv.org/abs/2503.16546)
- ğŸ–Šï¸LeNet(1989)
- ğŸ“…LeNet-5 (1998)
- GPU (2006)
- NVIDIA (2007)
- ImageNet(2010)
- AlexNet(2012)
  - AlexNet was trained in parallel on two NVIDIA GTX 580 GPUs 
- ZFNet(2013)
- â­GoogLeNet/Inception(2014)
  -  Inception V2 ==> V3 ==> V4 
- VGGNet (2014)
- Residual Neural Network (ResNet)(2015) |
- DenseNet(2016)
  - [Densely Connected Convolutional Networks(arXiv:1608.06993)](https://arxiv.org/abs/1608.06993)
  - ç›¸è¼ƒæ–¼ResNet, DenseNet å¯ç”¨æ›´å°‘çš„è¨“ç·´åƒæ•¸å–å¾—æ›´ä½³çš„æº–ç¢ºç‡
  - CVPR 2017 æœ€ä½³è«–æ–‡
  - Keras æä¾›æ•¸å€‹DenseNet ç‰ˆæœ¬ä¾›æˆ‘å€‘ä½¿ç”¨ï¼š DenseNet 121 ã€DenseNet 169 ã€DenseNet201
- SENetï¼ˆSqueeze-and-Excitation Networksï¼‰(2017)
  - ImageNet 2017 ç«¶è³½å† è»
  - [è«–æ–‡ Squeeze-and-Excitation Networks(arXiv:1709.01507)](https://arxiv.org/abs/1709.01507)
  - https://github.com/hujie-frank/SENet
- ShuffleNet(2017) ä¸€ç¨®é‡å°ç§»å‹•è¨­å‚™çš„æ¥µé«˜æ•ˆå·ç©ç¥ç¶“ç¶²è·¯
  - [è«–æ–‡ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices(arXiv:1707.01083)](https://arxiv.org/abs/1707.01083) 
- Vision Transformers (ViTs)(2020)
  - [è«–æ–‡An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale(arXiv:2010.11929)](https://arxiv.org/abs/2010.11929)
  - Vision Transformer architecture comprises several key stages:
    - Image Patching and Embedding
    - Positional Encoding
    - Transformer Encoder
    - Classification Head (MLP Head) 
  - https://blog.csdn.net/abc13526222160/article/details/131228810
- ä½¿ç”¨å…§å»ºMODEL
```
from tensorflow.keras.applications import Xception
xception = Xception()
xception.summary()
```
