### Transformer
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- Âü∫Êú¨ÊßãÂª∫ÂñÆÂÖÉ ==> Á∏ÆÊîæÈªûÁ©çÊ≥®ÊÑèÂäõÔºàscaled dot-product attentionÔºâÂñÆÂÖÉ
- ÈóúÈçµË¶ÅÁ¥†
  - ÂñÆÈ†≠Ëá™ÊàëÊ≥®ÊÑèÊ©üÂà∂ÔºöÊàëÂÄëÂ∞áÂ§öÈ†≠Ëá™ÊàëÊ≥®ÊÑèÁöÑÊ¶ÇÂøµÊèêÁÖâÂà∞ÂÖ∂Ê†∏ÂøÉÔºåÂ±ïÁ§∫‰∫ÜËá™ÊàëÊ≥®ÊÑèÂú®ËôïÁêÜÂ∫èÂàó‰∏≠ÁöÑÂü∫Êú¨‰Ωú„ÄÇ
  - ‰∏ÄÂÄãÁ∞°ÂñÆÁöÑ‰ΩçÁΩÆÂâçÈ•ãÁ∂≤Ë∑ØÔºöÈÄöÈÅéÂâçÈ•ãÁ∂≤Ë∑ØÁöÑÊ•µÁ∞°ÁâàÊú¨ÔºåÊàëÂÄëË™™ÊòéÁû≠ Transformers Â¶Ç‰ΩïÁç®Á´ãÂú∞Â∞çÊØèÂÄã‰ΩçÁΩÆÁöÑÊï∏ÊìöÈÄ≤Ë°åËΩâÊèõÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÊçïÁç≤Êï∏ÊìöÂÖßÈóú‰øÇÁöÑËÉΩÂäõ„ÄÇ
  - Skip Connections Âíå Layer NormalizationÔºöÈõÜÊàêÈÄô‰∫õÂü∫Êú¨ÂÖÉ‰ª∂‰ª•Á¢∫‰øùÊ®°ÂûãÁöÑË®ìÁ∑¥Á©©ÂÆöÊÄßÂíåÊïàÁéáÔºåÂ±ïÁ§∫‰∫ÜÂÆÉÂÄëÂú®‰øÉÈÄ≤Ê∑±Â∫¶Êû∂Êßã‰∏≠ÊúâÊïàÂ≠∏ÁøíÁöÑ‰ΩúÁî®„ÄÇ
  - Á∞°ÂñÆÁöÑ‰ΩçÁΩÆÁ∑®Á¢ºÔºöÊàëÂÄëÈÄöÈÅéÁµêÂêà‰∏ÄÁ®ÆÁ∞°ÂñÆÁöÑ‰ΩçÁΩÆÁ∑®Á¢ºÊñπÊ≥ïÔºåÂº∑Ë™ø‰∫Ü‰ΩçÁΩÆË≥áË®äÂú® Transformer Ê®°Âûã‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®ÔºåÁ¢∫‰øùÊàëÂÄëÁöÑÊ®°ÂûãËÉΩÂ§†Ë≠òÂà•Â∫èÂàó‰∏≠ÂÖÉÁ¥†ÁöÑÈ†ÜÂ∫è„ÄÇ 

### Â∞éËÆÄ
- üëç[Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
- üëç[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- https://ithelp.ithome.com.tw/articles/10363257

## Âª∂‰º∏Èñ±ËÆÄ
- [A Survey of Transformers](https://arxiv.org/abs/2106.04554)
- [A Survey on Visual Transformer](https://arxiv.org/abs/2012.12556)
- [Transformers in Time Series: A Survey](https://arxiv.org/abs/2202.07125)
- [Long Range Arena: A Benchmark for Efficient Transformers](https://arxiv.org/abs/2011.04006)

## ÁØÑ‰æã:ÊáâÁî®
- [Natural Language Processing with Transformers, Revised Edition](https://learning.oreilly.com/library/view/natural-language-processing/9781098136789/)
   - https://github.com/nlp-with-transformers/notebooks
   - 01_introduction.ipynb

## ÁØÑ‰æã: ÂØ¶‰Ωú‰∏ÄÂÄãKeras Transformer
- Attention Layers in TensorFlow
  - Self-Attention (Scaled Dot-Product Attention) --> tf.keras.layers.Attention
  - Multi-Head Attention  --> tf.keras.layers.MultiHeadAttention
  - https://www.geeksforgeeks.org/attention-layers-in-tensorflow/
- [Text classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer/)

## ÁØÑ‰æã: Tensorflow  Transformer
- [Neural machine translation with attention](https://www.tensorflow.org/text/tutorials/nmt_with_attention)
- [Neural machine translation with a Transformer and Keras](https://www.tensorflow.org/text/tutorials/transformer)

## ÁØÑ‰æã: ÂØ¶‰Ωú‰∏ÄÂÄãPyTorch Transformer
- [Building a Simple Transformer using PyTorch [Code Included]](https://pureai.substack.com/p/building-a-simple-transformer-using-pytorch)
- https://github.com/ermattson/pure-ai-tutorials/tree/main/SimpleTransformer-PyTorch

## ÂèÉËÄÉÊõ∏
- [Natural Language Processing with Transformers, Revised Edition](https://learning.oreilly.com/library/view/natural-language-processing/9781098136789/)
  - https://github.com/nlp-with-transformers/notebooks
- [Hands-On Generative AI with Transformers and Diffusion Models](https://learning.oreilly.com/library/view/hands-on-generative-ai/9781098149239/)
  - https://github.com/genaibook/genaibook
- [Mastering Transformers - Second Edition](https://learning.oreilly.com/library/view/mastering-transformers/9781837633784/)
  - https://github.com/PacktPublishing/Mastering-Transformers-Second-Edition
- [Transformers for Natural Language Processing and Computer Vision - Third Edition](https://learning.oreilly.com/library/view/transformers-for-natural/9781805128724/)
  - https://github.com/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/
- [Hands-On Large Language Models](https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/)
