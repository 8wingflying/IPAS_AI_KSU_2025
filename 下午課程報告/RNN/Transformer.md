### Transformer
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- åŸºæœ¬æ§‹å»ºå–®å…ƒ ==> ç¸®æ”¾é»ç©æ³¨æ„åŠ›ï¼ˆscaled dot-product attentionï¼‰å–®å…ƒ
- é—œéµè¦ç´ 
  - å–®é ­è‡ªæˆ‘æ³¨æ„æ©Ÿåˆ¶ï¼šæˆ‘å€‘å°‡å¤šé ­è‡ªæˆ‘æ³¨æ„çš„æ¦‚å¿µæç…‰åˆ°å…¶æ ¸å¿ƒï¼Œå±•ç¤ºäº†è‡ªæˆ‘æ³¨æ„åœ¨è™•ç†åºåˆ—ä¸­çš„åŸºæœ¬ä½œã€‚
  - ä¸€å€‹ç°¡å–®çš„ä½ç½®å‰é¥‹ç¶²è·¯ï¼šé€šéå‰é¥‹ç¶²è·¯çš„æ¥µç°¡ç‰ˆæœ¬ï¼Œæˆ‘å€‘èªªæ˜ç­ Transformers å¦‚ä½•ç¨ç«‹åœ°å°æ¯å€‹ä½ç½®çš„æ•¸æ“šé€²è¡Œè½‰æ›ï¼Œå¾è€Œå¢å¼·æ¨¡å‹æ•ç²æ•¸æ“šå…§é—œä¿‚çš„èƒ½åŠ›ã€‚
  - Skip Connections å’Œ Layer Normalizationï¼šé›†æˆé€™äº›åŸºæœ¬å…ƒä»¶ä»¥ç¢ºä¿æ¨¡å‹çš„è¨“ç·´ç©©å®šæ€§å’Œæ•ˆç‡ï¼Œå±•ç¤ºäº†å®ƒå€‘åœ¨ä¿ƒé€²æ·±åº¦æ¶æ§‹ä¸­æœ‰æ•ˆå­¸ç¿’çš„ä½œç”¨ã€‚
  - ç°¡å–®çš„ä½ç½®ç·¨ç¢¼ï¼šæˆ‘å€‘é€šéçµåˆä¸€ç¨®ç°¡å–®çš„ä½ç½®ç·¨ç¢¼æ–¹æ³•ï¼Œå¼·èª¿äº†ä½ç½®è³‡è¨Šåœ¨ Transformer æ¨¡å‹ä¸­çš„é—œéµä½œç”¨ï¼Œç¢ºä¿æˆ‘å€‘çš„æ¨¡å‹èƒ½å¤ è­˜åˆ¥åºåˆ—ä¸­å…ƒç´ çš„é †åºã€‚ 

### å°è®€
- ğŸ‘[Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
- ğŸ‘[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- https://ithelp.ithome.com.tw/articles/10363257

## å»¶ä¼¸é–±è®€
- [A Survey of Transformers](https://arxiv.org/abs/2106.04554)
- [A Survey on Visual Transformer](https://arxiv.org/abs/2012.12556)
- [Transformers in Time Series: A Survey](https://arxiv.org/abs/2202.07125)
- [Long Range Arena: A Benchmark for Efficient Transformers](https://arxiv.org/abs/2011.04006)

## ç¯„ä¾‹:æ‡‰ç”¨
- [Natural Language Processing with Transformers, Revised Edition](https://learning.oreilly.com/library/view/natural-language-processing/9781098136789/)
   - https://github.com/nlp-with-transformers/notebooks
   - 01_introduction.ipynb

## ç¯„ä¾‹: å¯¦ä½œä¸€å€‹Keras Transformer
- Attention Layers in TensorFlow
  - Self-Attention (Scaled Dot-Product Attention) --> tf.keras.layers.Attention
  - Multi-Head Attention  --> tf.keras.layers.MultiHeadAttention
  - https://www.geeksforgeeks.org/attention-layers-in-tensorflow/
- [Text classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer/)

## ç¯„ä¾‹: Tensorflow  Transformer
- [Neural machine translation with attention](https://www.tensorflow.org/text/tutorials/nmt_with_attention)
- [Neural machine translation with a Transformer and Keras](https://www.tensorflow.org/text/tutorials/transformer)

## ç¯„ä¾‹: å¯¦ä½œä¸€å€‹PyTorch Transformer
- [Building a Simple Transformer using PyTorch [Code Included]](https://pureai.substack.com/p/building-a-simple-transformer-using-pytorch)
- https://github.com/ermattson/pure-ai-tutorials/tree/main/SimpleTransformer-PyTorch

## åƒè€ƒæ›¸
- [Natural Language Processing with Transformers, Revised Edition](https://learning.oreilly.com/library/view/natural-language-processing/9781098136789/)
  - https://github.com/nlp-with-transformers/notebooks
  - ç¬¬ä¸€ç‰ˆç°¡é«”ä¸­è­¯æœ¬
- [Hands-On Generative AI with Transformers and Diffusion Models](https://learning.oreilly.com/library/view/hands-on-generative-ai/9781098149239/)
  - https://github.com/genaibook/genaibook
- [Mastering Transformers - Second Edition](https://learning.oreilly.com/library/view/mastering-transformers/9781837633784/)
  - https://github.com/PacktPublishing/Mastering-Transformers-Second-Edition
- [Transformers for Natural Language Processing and Computer Vision - Third Edition](https://learning.oreilly.com/library/view/transformers-for-natural/9781805128724/)
  - https://github.com/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition/
- [Hands-On Large Language Models](https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/)
  - [ç« ç¯€å…§å®¹](LLM_BOOK_Content.md) 
