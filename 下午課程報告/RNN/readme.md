## RNN èˆ‡ è‡ªç„¶èªžè¨€è™•ç†|å ±å‘Šä¸»é¡Œ
- NLP
  - https://www.geeksforgeeks.org/natural-language-processing-nlp-tutorial/ 
- [Text Representation or Text Embedding Techniques(word ==> vector) ](NLP_WordVector.md)
  - https://medium.com/ml-note/word-embedding-3ca60663999d
  - Bag of Word
  - TF-IDF
  - Word Embedding 
- RNN  ==> The Problem of Long-Term Dependencies
  - Vanilla RNN
  - LSTM|Long Short-Term Memory|é•·çŸ­æœŸè¨˜æ†¶(1997)
    - ðŸ‘ðŸ‘ [Understanding LSTM Networks(2015)](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
    - https://ithelp.ithome.com.tw/articles/10193924 
  - GRU | Gated Recurrent Unit(2014)
    - https://zhuanlan.zhihu.com/p/20310288990
    - https://ithelp.ithome.com.tw/articles/10194201 
  - https://www.geeksforgeeks.org/rnn-vs-lstm-vs-gru-vs-transformers/
- Neural Machine Translation èˆ‡ seq2seq model
  - 2014 [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
  - 2014 [Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation](https://emnlp2014.org/papers/pdf/EMNLP2014179.pdf)
  - https://research.google/blog/a-neural-network-for-machine-translation-at-production-scale/
- Attention
  - 2014 [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
  - 2015 [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)
  - ðŸ‘[Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
- 2017 [Transformer](Transformer.md)
  - ðŸ‘ðŸ‘ðŸ‘[Attention Is All You Need](https://arxiv.org/abs/1706.03762)
  - [[1607.06450] Layer Normalization | Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton](https://arxiv.org/abs/1607.06450)
  - ðŸ‘[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Pre-Trained Language Models](Pre-Trained_Language_Models.md) ==> LLM
  - **2018 BERT Bidirectional Encoder Representations from Transforme**
- NLP|æ–‡æœ¬åˆ†é¡ž(TEXT Classofication)
  - [IMDbæ–‡æœ¬åˆ†é¡ž](IMDbæ–‡æœ¬åˆ†é¡ž.md)
    - Sentiment Analysis æƒ…ç·’åˆ†æž ==> è² è©• vs æ­£è©•
    - ä»¥å…§å®¹ç‚ºåŸºç¤Žçš„æŽ¨è–¦ç³»çµ±
- NLP|æ–‡æœ¬ç”Ÿæˆ(TEXT Generation) ==> GenAI


## æ•™ç§‘æ›¸ç›¸é—œç« ç¯€
#### æ•™ç§‘æ›¸:ç¬¬15ç« Processing Sequences Using RNNs and CNNs ==> [æ™‚é–“åºåˆ—åˆ†æž](æ™‚é–“åºåˆ—åˆ†æž.md)
- Recurrent Neurons and Layers
- Training RNNs
- Forecasting a Time Series
- Handling Long Sequences

#### æ•™ç§‘æ›¸:ç¬¬16ç« 
- Generating Shakespearean Text Using a Character RNN
- Sentiment Analysis
- An Encoderâ€“Decoder Network for Neural Machine Translation
- Attention Mechanisms
- An Avalanche of Transformer Models
- Vision Transformers
- Hugging Faceâ€™s Transformers Library

## å»¶ä¼¸é–±è®€
- [Natural Language Processing in Action, Second Edition(2025)](https://learning.oreilly.com/library/view/natural-language-processing/9781617299445/)
- [Natural Language Processing with Transformers, Revised Edition(2022)](https://learning.oreilly.com/library/view/natural-language-processing/9781098136789/)
- [Python Natural Language Processing Cookbook - Second Edition(2024)](https://learning.oreilly.com/library/view/python-natural-language/9781803245744/)
- [Practical Natural Language Processing(2020)](https://learning.oreilly.com/library/view/practical-natural-language/9781492054047/)
- å‚³çµ±NLP ==> NLTK, spaCy, sklearn, and gensim
  - [Python Natural Language Processing Cookbook(2021)](https://learning.oreilly.com/library/view/python-natural-language/9781838987312/)
  - [Natural Language Processing: Python and NLTK(2016)](https://learning.oreilly.com/library/view/natural-language-processing/9781787285101/) 

## å»¶ä¼¸é–±è®€2:Large Language Model
- [Build a Large Language Model (From Scratch)(2024)](https://learning.oreilly.com/library/view/build-a-large/9781633437166/)
- [Hands-On Large Language Models(2024)](https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/)
  - [ç« ç¯€å…§å®¹](LLM_BOOK_Content.md) 
- [Designing Large Language Model Applications(2025)](https://learning.oreilly.com/library/view/designing-large-language/9781098150495/)
- [The Developer's Playbook for Large Language Model Security(2024)](https://learning.oreilly.com/library/view/the-developers-playbook/9781098162191/)
- [Prompt Engineering for LLMs](https://learning.oreilly.com/library/view/prompt-engineering-for/9781098156145/)
- [Prompt Engineering for Generative AI](https://learning.oreilly.com/library/view/prompt-engineering-for/9781098153427/)
