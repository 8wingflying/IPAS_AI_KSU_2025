## RNN 與 自然語言處理|報告主題
- NLP
  - https://www.geeksforgeeks.org/natural-language-processing-nlp-tutorial/ 
- [Text Representation or Text Embedding Techniques(word ==> vector) ](NLP_WordVector.md)
  - https://medium.com/ml-note/word-embedding-3ca60663999d
  - Bag of Word
  - TF-IDF
  - Word Embedding 
- RNN
  - Vanilla RNN
  - LSTM
    - https://ithelp.ithome.com.tw/articles/10193924 
  - GRU (Gated Recurrent Unit)
    - https://zhuanlan.zhihu.com/p/20310288990
    - https://ithelp.ithome.com.tw/articles/10194201 
  - https://www.geeksforgeeks.org/rnn-vs-lstm-vs-gru-vs-transformers/
- Neural Machine Translation 與 seq2seq model
  - 2014 [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
  - 2014 [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
- 2017 [Transformer](Transformer.md)
  - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
  - 基本構建單元 ==> 縮放點積注意力（scaled dot-product attention）單元
- [Pre-Trained Language Models](Pre-Trained_Language_Models.md) ==> LLM
  - **2018 BERT Bidirectional Encoder Representations from Transforme**
- NLP|文本分類(TEXT Classofication)
  - [IMDb文本分類](IMDb文本分類.md)
    - Sentiment Analysis 情緒分析 ==> 負評 vs 正評
    - 以內容為基礎的推薦系統
- NLP|文本生成(TEXT Generation) ==> GenAI


## 教科書相關章節
#### 教科書:第15章Processing Sequences Using RNNs and CNNs ==> 時間序列分析
- Recurrent Neurons and Layers
- Training RNNs
- Forecasting a Time Series
- Handling Long Sequences

#### 教科書:第16章
- Generating Shakespearean Text Using a Character RNN
- Sentiment Analysis
- An Encoder–Decoder Network for Neural Machine Translation
- Attention Mechanisms
- An Avalanche of Transformer Models
- Vision Transformers
- Hugging Face’s Transformers Library


